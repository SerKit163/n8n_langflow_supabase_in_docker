services:
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    environment:
      - N8N_HOST=0.0.0.0
      - N8N_PORT=5678
      - N8N_PROTOCOL=${N8N_PROTOCOL:-https}
      - WEBHOOK_URL=${WEBHOOK_URL:-}
    # ВАЖНО: Не открываем порт наружу напрямую! Прокси через Caddy.
    # ports:
    #   - "${N8N_PORT}:5678"
    deploy:
      resources:
        limits:
          memory: ${N8N_MEMORY_LIMIT}
          cpus: '${N8N_CPU_LIMIT}'
        reservations:
          memory: ${N8N_MEMORY_LIMIT}
          cpus: '${N8N_CPU_LIMIT}'
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - proxy
    restart: unless-stopped
    entrypoint: |
      sh -c "
        chown -R node:node /home/node/.n8n || true
        chmod -R 755 /home/node/.n8n || true
        exec tini -- /docker-entrypoint.sh
      "
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  langflow:
    image: langflowai/langflow:latest
    container_name: langflow
    user: "0"
    # ВАЖНО: Не открываем порт наружу напрямую! Прокси через Caddy.
    # ports:
    #   - "7860:7860"
    environment:
      - LANGFLOW_HOST=0.0.0.0
      - LANGFLOW_PORT=7860
      - LANGFLOW_CACHE_TYPE=memory
      - LANGFLOW_LANGCHAIN_CACHE=memory
      - LANGFLOW_BACKEND_CORS_ORIGINS=${LANGFLOW_CORS_ORIGINS:-*}
      - LANGFLOW_FRONTEND_TIMEOUT=60000
      - LANGFLOW_WORKERS=1
      - LANGFLOW_WORKER_TIMEOUT=300
      - LANGFLOW_COMPONENTS_PATH=/app/.venv/lib/python3.12/site-packages/langflow/components
      - LANGFLOW_LOAD_FLOWS_ON_STARTUP=false
      - LANGFLOW_AUTO_LOGIN=true
      - LANGFLOW_DISABLE_COMPOSIO=true
      - LANGFLOW_CONFIG_DIR=/app/data/.langflow
      - PYTHONUNBUFFERED=1
    entrypoint: |
      /bin/sh -c "
        # Проверяем, что мы root
        if [ \"$$(id -u)\" != \"0\" ]; then
          echo 'ERROR: Must run as root to fix permissions'
          exit 1
        fi
        # Сначала исправляем права на /app/data если volume уже существует
        if [ -d /app/data ]; then
          chown -R root:root /app/data || true
          chmod -R 777 /app/data || true
        fi
        # Создаем все необходимые директории
        mkdir -p /app/data/.cache/langflow
        mkdir -p /app/data/logs
        mkdir -p /app/data/.langflow
        # Устанавливаем права на всю директорию /app/data (777 для гарантии работы)
        chown -R root:root /app/data
        chmod -R 777 /app/data
        # Запускаем langflow от root (образ может переключиться сам)
        exec langflow run --host 0.0.0.0 --port 7860 --workers 1
      "
    deploy:
      resources:
        limits:
          memory: ${LANGFLOW_MEMORY_LIMIT}
          cpus: '${LANGFLOW_CPU_LIMIT}'
        reservations:
          memory: ${LANGFLOW_MEMORY_LIMIT}
          cpus: '${LANGFLOW_CPU_LIMIT}'
    volumes:
      - langflow_data:/app/data
    networks:
      - proxy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:7860/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  supabase-db:
    image: ghcr.io/supabase/postgres:15.1.0.119
    container_name: supabase-db
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=postgres
      - POSTGRES_HOST=/var/run/postgresql
      - PGDATA=/var/lib/postgresql/data/pgdata
    ports:
      - "${SUPABASE_PORT}:5432"
    deploy:
      resources:
        limits:
          memory: ${SUPABASE_MEMORY_LIMIT}
          cpus: '${SUPABASE_CPU_LIMIT}'
        reservations:
          memory: ${SUPABASE_MEMORY_LIMIT}
          cpus: '${SUPABASE_CPU_LIMIT}'
    volumes:
      - supabase_data:/var/lib/postgresql/data
    networks:
      - proxy
    restart: unless-stopped
    entrypoint: |
      sh -c "
        if [ ! -d /var/lib/postgresql/data/pgdata ]; then
          mkdir -p /var/lib/postgresql/data/pgdata
        fi
        chown -R postgres:postgres /var/lib/postgresql/data
        chmod 700 /var/lib/postgresql/data/pgdata
        exec docker-entrypoint.sh postgres -c listen_addresses='*'
      "
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  supabase-studio:
    image: ghcr.io/supabase/studio:20240513-d025e0f
    container_name: supabase-studio
    environment:
      - SUPABASE_URL=http://supabase-rest:3000
      - SUPABASE_PUBLIC_URL=${SUPABASE_PUBLIC_URL:-https://localhost:3000}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - STUDIO_PGUSER=postgres
      - STUDIO_PGPASSWORD=${POSTGRES_PASSWORD}
      - STUDIO_USERNAME=${SUPABASE_ADMIN_LOGIN:-admin}
      - STUDIO_PASSWORD=${SUPABASE_ADMIN_PASSWORD}
      - DEFAULT_ORGANIZATION_NAME=Default Organization
      - DEFAULT_PROJECT_NAME=Default Project
      - SUPABASE_DB_URL=postgresql://postgres:${POSTGRES_PASSWORD}@supabase-db:5432/postgres
      - SUPABASE_DB_PASSWORD=${POSTGRES_PASSWORD}
    # ВАЖНО: Не открываем порт наружу напрямую! Прокси через Caddy.
    # ports:
    #   - "127.0.0.1:${SUPABASE_KB_PORT:-3000}:3000"
    depends_on:
      - supabase-rest
      - supabase-db
    networks:
      - proxy
    restart: unless-stopped

  supabase-auth:
    image: ghcr.io/supabase/gotrue:v2.162.0
    container_name: supabase-auth
    depends_on:
      - supabase-db
    environment:
      - GOTRUE_DB_DRIVER=postgres
      - GOTRUE_DB_DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@supabase-db:5432/postgres
      - GOTRUE_SITE_URL=${SUPABASE_PUBLIC_URL:-https://localhost:8000}
      - API_EXTERNAL_URL=${SUPABASE_PUBLIC_URL:-https://localhost:8000}
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@supabase-db:5432/postgres
      - GOTRUE_JWT_SECRET=${JWT_SECRET}
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=info
    networks:
      - proxy
    restart: unless-stopped

  supabase-rest:
    image: ghcr.io/supabase/postgrest:v12.2.0
    container_name: supabase-rest
    depends_on:
      - supabase-db
    environment:
      - PGRST_DB_URI=postgresql://postgres:${POSTGRES_PASSWORD}@supabase-db:5432/postgres
      - PGRST_DB_SCHEMAS=public,storage,graphql_public
      - PGRST_DB_ANON_ROLE=anon
      - PGRST_SERVER_HOST=0.0.0.0
      - PGRST_SERVER_PORT=3000
    networks:
      - proxy
    restart: unless-stopped

  ollama:
    image: ${OLLAMA_IMAGE:-ollama/ollama:latest}
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    # ВАЖНО: Не открываем порт наружу напрямую! Прокси через Caddy.
    # ports:
    #   - "${OLLAMA_PORT}:11434"
    deploy:
      resources:
        limits:
          memory: ${OLLAMA_MEMORY_LIMIT}
          cpus: '${OLLAMA_CPU_LIMIT}'
        reservations:
          memory: ${OLLAMA_MEMORY_LIMIT}
          cpus: '${OLLAMA_CPU_LIMIT}'
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - proxy
    restart: unless-stopped
    entrypoint: |
      sh -c "
        mkdir -p /root/.ollama
        chmod -R 755 /root/.ollama || true
        exec /bin/ollama serve
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  caddy:
    image: caddy:latest
    container_name: caddy
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - proxy
    restart: unless-stopped
    environment:
      - CADDY_EMAIL=${LETSENCRYPT_EMAIL:-}
    # DNS настройки для надежного разрешения доменов ACME серверов
    dns:
      - 8.8.8.8
      - 1.1.1.1

volumes:
  n8n_data:
    driver: local
  langflow_data:
    driver: local
  supabase_data:
    driver: local
  caddy_data:
    driver: local
  caddy_config:
    driver: local
  ollama_data:
    driver: local

networks:
  proxy:
    driver: bridge
